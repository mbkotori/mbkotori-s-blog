# 20210111
## 1.pytorch各个损失函数都有自己的前提，有时候不能混用
  举例：CrossEntropyLoss，该函数进行验证时label必须是以0开始的，即
  classes=【0，1，2，3】
  否则报错：Assertion `cur_target >= 0 && cur_target < n_classes’ failed.

## 2.数据选择转换格式时
dtype而不是detype，注意拼写

## 3.多分类时使用np.argmax（）
，返回numpy数组中最大值的索引，根据索引即可代表网络最后给该像素的类型值

## 4.代码未完全确认可以使用时，优先构建小数据集来快速验证可行性
不要出现今天这种跑了4k数据才发现eval模块出错的情况

## 5.softmax和sigmoid：
softmax用于多分类，把多个输出映射到（0，1）区间内且这些输出的结果和为1（满足概率的特性）
和上面联动：softmax后再使用argmax来找到某个概率值最大的分类索引，得到判断结果
sigmoid：注意，是sigmoid，不是sigmiod也不是sigmod，容易写错
sigmoid就是逻辑斯蒂函数，即logistic函数，把一个实数映射到（0，1）的区间，拿来做二分类，但是注意，你拿来做多分类也行，只是多分类的值相加，不会像softmax一样各分类总值相加为1，一般来说，拿来二分类还需要给他设置个阈值，将（0，1）的值映射成0/1或者0/255
另一个方法，二分类也是多分类，那你用softmax啊！但是这时候，你的网络输出应该是2层，即最后的out_channel=2，然后argmax取值作为分类，是个好办法

## 5.1 知乎说法：
sigmoid的优点在于输出范围有限，所以数据在传递的过程中不容易发散。当然也有相应的缺点，就是饱和的时候梯度太小。sigmoid还有一个优点是输出范围为(0, 1)，所以可以用作输出层，输出表示概率。评论中 @林孟潇指出了sigmoid的另一个优点：求导容易。
作者：王赟 Maigo
链接：https://www.zhihu.com/question/24259872/answer/82598145



# 20210116
## tensor和numpy转换
使用numpy()和from_numpy()相互转换,这两函数生成结果和源数据是共享内存的(速度快,但是改变一个另一个也改变)

另一方法是torch.tensor(),该方法是先数据拷贝,时间空间消耗大,也不共享内存

除了CharTensor外,所有在CPU上的tensor都可以和numpy数组转换
(感想:自由啊,回想起tensorflow中连print都打印不出内容的情况,pytorch某种程度上方便太多了!)

用to()将tensor在GPU,CPU上移动,当然你得有gpu
指定device: `device = torch.device('cuda')`
移动: `x=x.to(device)`
这就把实现了一次移动

## autograd
这个包能根据输入和前向传播自动构建计算图和执行反向传播
核心类:tensor
将属性`.requires_grad`设置`True`就会追踪`tensor`的操作(那么就可以利用链式法则进行梯度传播),调用`.backward()`完成梯度计算,`tensor`的梯度会积累到`.grad`属性中
如果要取消追踪,就要调用.`detach()`从追踪记录分离,也可以使用`with torch.no_grad()`将不想追踪的代码包裹起来,这在评估模型(eval)时很有用

补充资料:PyTorch 的 backward 为什么有一个 grad_variables 参数？
<https://zhuanlan.zhihu.com/p/29923090>

    我觉得这部分我看的是挺头晕的,这部分的逻辑还是要再深入看看的

## 什么是超参数
需要强调的是，这里的批量大小和学习率的值是**人为设定的**，并不是通过模型训练学出的，因此叫作超参数（hyperparameter）。**我们通常所说的“调参”指的正是调节超参数**，例如通过反复试错来找到超参数合适的值。在少数情况下，超参数也可以通过模型训练学出。本书对此类情况不做讨论。
来源:<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.1_linear-regression?id=_3-%e4%bc%98%e5%8c%96%e7%ae%97%e6%b3%95>
    之后有机会可以详细写一篇关于超参数的整合文章

## 计算代码运行时间
`start = time()`
`应该运行的代码块`
`print(time() - start)`

## python的yield关键字
起因是看到这样一段代码：
来源是：<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.2_linear-regression-scratch?id=_322-%e8%af%bb%e5%8f%96%e6%95%b0%e6%8d%ae>

```python
# 本函数已保存在d2lzh包中方便以后使用
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)  # 样本的读取顺序是随机的
    for i in range(0, num_examples, batch_size):
        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 最后一次可能不足一个batch
        yield  features.index_select(0, j), labels.index_select(0, j)
```
这是一个简单的dataloader函数，但是在最后返回值上，我们可以看到他并没使用return，而是用了yield关键字

关于yield，得讨论到生成器generator，他是记录一定的算法规则，和一般的迭代器不同的是，他是在需要调用时再根据算法推算出相应元素，而不用一口气算完
yield类似return，回想一下return，函数中执行到这个关键字就会返回响应结果并终止函数执行

当yield被塞入函数里，会发生什么呢->该函数变成了生成器->我们能用next使用它或遍历

考虑到生成器的目的：记录一定算法规则得到按需生成的列表
所以yield一般在for循环语句以一定规则生成，之后调用函数，得到一个生成器，再遍历生成器使用它

### 当然，yield也可以用在别的地方，生成器只是一种使用方法

`就像打电玩一样，你蓄力发大招的时候，如果执行了return，就直接把大招发出去了，蓄力结束
如果执行了yield，就相当于返回一个生成器对象，每调用一次next（），就发一个大招`（来源知乎）

与return不同，yield在函数中返回值时会保存函数的状态，使下一次调用函数时会从上一次的状态继续执行，即从yield的下一条语句开始执行，这样做有许多好处，比如我们想要生成一个数列，若该数列的存储空间太大，而我们仅仅需要访问前面几个元素，那么yield就派上用场了，它实现了这种一边循环一边计算的机制，节省了存储空间，提高了运行效率。

总结整理我们最开始的这段代码：
我们包装的这么一个dataloader，应该将我们的数据根据需要的batchsize分成一段一段的数据（如1000数据，bs=4，就是250组），然后每次输出一组数据，这时候根据yield会保存到该组数据位置的状态，然后该组进入网络运算过程，实现网络和反向传播后，再循环回来找dataloader要下一组数据，yield的功能就体现出来了，因为我们从直接的状态就可以直接读下一组而不是从头按照索引找新的一组数据。这样

注：在pytorch中，我们的dataloader库也使用了类似这样的方法



# 20210118
## pytorch搭建网络（定义模型）
（1）导入`torch.nn`模块，nn就是利用autograd定义模型，nn的核心数据结构是`Module`，这是一个抽象概念，可以表示神经网络中某个词或者包含多层的神经网络。
实际运用时，最常见做法是继承nn.Module，一个nn.Module实例应该包含一些层以及返回输出的前向传播（forward）方法
### 这部分以后我得好好理清楚面向对象的部分
个人理解：nn.Module就是标准积木，现在我们的模型就是某个我们设计好的模型玩具，要想搭成这个玩具，我们先得从标准积木（nn.Module）中构建出我们要的指定模块(网络层)，最后forward方法就是自己搞出来的‘拼装手册’，怎么把我们的积木拼成我们的玩具。

#### 想想8x8微型积木就好了
![](http://ys-d.ys168.com/614621432/813403427/k64523X6JGVNWFlpglqo59/1610940088437.jpg)

当然，简单方法就是nn.Sequential，这个最方便，直接net=nn.Sequential（网络层），网络层按你传入的顺序添加到计算图中
可以通过net.parameters()来查看模型所有的可学习参数，此函数将返回一个生成器。
```python
for param in net.parameters():
    print(param)
```

## 给不同子网络设置不同学习率（finetune常用）
举例：
```python
optimizer =optim.SGD([
                # 如果对某个参数不指定学习率，就使用最外层的默认学习率
                {'params': net.subnet1.parameters()}, # lr=0.03
                {'params': net.subnet2.parameters(), 'lr': 0.01}
            ], lr=0.03)
```
    似乎在pytorch中，也有类似的方法用于将多个子网络训练，之后可以进行研究

## torch中的各种轮子（深度学习框架就是这么用的嘛）
torch.utils.data模块提供了有关数据处理的工具，torch.nn模块定义了大量神经网络的层，torch.nn.init模块定义了各种初始化方法，torch.optim模块提供了很多常用的优化算法。

## Softmax特点
softmax运算常被用在分类问题，他的好处就是将我们多分类的输出值变换成正值且和为一的概率分布
之后我们可以通过取最大概率作为分类判断依据
参考网页：<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.4_softmax-regression?id=_342-softmax%e5%9b%9e%e5%bd%92%e6%a8%a1%e5%9e%8

# 20210119
## 今天更了一篇新文章
其实一开始只是想研究下latex写在每日总结里,结果稀里糊涂连着换了主题,忙了半下午,索性弄了一篇文章出来

## 关于损失函数(平方损失和交叉熵)
进行预测概率时(分类),选择平方损失函数就过于严格,例如y1=y2=0.2和y1=0,y2=0.4的损失就差距很大,但是两者的分类结果相同
换用交叉熵的话,根据公式他将只关心正确类别的概率,更为合理
来源:<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.4_softmax-regression?id=_345-%e4%ba%a4%e5%8f%89%e7%86%b5%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0>
# 20210120
## 表示图片时对格式的注意
注意： 由于像素值为0到255的整数，所以刚好是uint8所能表示的范围，包括transforms.ToTensor()在内的一些关于图片的函数就默认输入的是uint8型，若不是，可能不会报错但可能得不到想要的结果。所以，如果用像素值(0-255整数)表示图片数据，那么一律将其类型设置成uint8，避免不必要的bug。 本人就被这点坑过，详见<a href="https://tangshusen.me/2018/12/05/kaggle-doodle-reco/" target="_target">我的这个博客2.2.4节</a>。

以上摘自<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.5_fashion-mnist?id=_351-%e8%8e%b7%e5%8f%96%e6%95%b0%e6%8d%ae%e9%9b%86>.

## 什么是模型微调
<a href="https://zhuanlan.zhihu.com/p/35890660">CNN入门讲解：什么是微调（Fine Tune）？</a>

## pytorch中的gather和scatter函数
先看看gather:
gather,单词中文释义为:聚集,集合
官方文档:
```python
torch.gather(input, dim, index, out=None) → Tensor
 
 Gathers values along an axis specified by dim.
 
 For a 3-D tensor the output is specified by:
 
 out[i][j][k] = input[index[i][j][k]][j][k] # dim=0
 out[i][j][k] = input[i][index[i][j][k]][k] # dim=1
 out[i][j][k] = input[i][j][index[i][j][k]] # dim=2
 
 Parameters: 
 
  input (Tensor) – The source tensor
  dim (int) – The axis along which to index
  index (LongTensor) – The indices of elements to gather
  out (Tensor, optional) – Destination tensor
 
 Example:
 
 >>> t = torch.Tensor([[1,2],[3,4]])
 >>> torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))
  1 1
  4 3
 [torch.FloatTensor of size 2x2]
```

可以看到,gather是根据我们给的索引index在input中数据得到out,其中除了index外输出还会受到dim的影响,下面用张图直观表示下
![](http://ys-f.ys168.com/614621469/813404410/iohprkk534471377NHVd0/gather%E8%A7%A3%E9%87%8A%E5%9B%BE.png)

再看看scatter:
scatter中文释义:撒,撒播,散开

这个函数则是将数据根据索引回填到一个新矩阵中,根据它的功能我们很适合拿他来做onehot矩阵
同样应有输入input,操作维度dim,索引index,我们同样利用一张图片李姐:
![](http://ys-j.ys168.com/614621458/813404548/w7425552H85NJmndqtlb8/scatter%E8%A7%A3%E9%87%8A%E5%9B%BE.jpg)

以下列出几个参考网站,方便读者进行进一步阅读理解:
[Pytorch的gather和scatter](https://blog.csdn.net/loovelj/article/details/107639701)
[3分钟理解 pytorch 的 gather 和 scatter](https://zhuanlan.zhihu.com/p/319191164)
[torch.gather/scatter_使用](https://zhuanlan.zhihu.com/p/59346637)

## 一个没看懂的代码
```python
def accuracy(y_hat, y):
    return (y_hat.argmax(dim=1) == y).float().mean().item()
```
用来计算`y_hat`和`y`的准确率
```python
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])
y = torch.LongTensor([0, 2])
```

理一下思路,首先其中y_hat.argmax(dim=1)返回矩阵y_hat每行中最大元素的索引，且返回结果与变量y形状相同。
即`print(y_hat.argmax(dim=1)) = tensor([2,2])`
然后做相等判断式,和y进行比较,判断式输出为:[False, true],是一个类型为`ByteTensor`的Tensor，我们用float()将其转换为值为0（相等为假）或1（相等为真）的浮点型Tensor。
也就是到此处为:print((y_hat.argmax(dim=1) == y).float()) = tensor([0., 1.])
注:`ByteTensor`在c语言中对应的话,可以看作无符号字符串
对tensor([0., 1.])做torch.mean()操作,默认不设置dim时返回所有元素的平均值,设置dim后则按维度给返回值
此处输出则为(0+1)/2=0.5.
```python
print(accuracy(y_hat, y))
```
输出:
```python
0.5
```
最后结尾的item()用法则是得到一个元素张量里面的元素值,如果不使用item,输出应为:
```python
tensor(0.5000)
```

# 20210121
## 分开定义softmax运算和交叉熵损失函数可能会造成数值不稳定
摘自:<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.7_softmax-regression-pytorch?id=_373-softmax%e5%92%8c%e4%ba%a4%e5%8f%89%e7%86%b5%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0>

### 暂未解决,后续查资料了解下

先写下softmax函数的公式,假设我们有一数组V,$V_{i}$表示V中第i个元素,那么该元素的softmax值是:
$$S_{i}=\frac{e^{i}}{\sum_{j}^{}e^{j} } $$

其中原mxnet版本,沐神给的问题是:
```
3.6.10. 练习
- 在本节中，我们直接按照softmax运算的数学定义来实现softmax函数。这可能会造成什么问题？（提示：试一试计算 exp(50) 的大小。）
- 本节中的cross_entropy函数是按照“softmax回归”一节中的交叉熵损失函数的数学定义实现的。这样的实现方式可能有什么问题？（提示：思考一下对数函数的定义域。）
- 你能想到哪些办法来解决上面的两个问题？
```
第一个问题很明显,exp(50)数值计算溢出(即x较大),为了解决这个问题的方法就是改变x的值咯,搬运知乎一份回答:<https://zhuanlan.zhihu.com/p/27223959>
![](http://ys-o.ys168.com/614621441/813405382/krcmuns453633755MJa1/softmax%E4%BC%98%E5%8C%96.png)
公式变换:
```python
def softmax(X):
    X = X-X.max()
    exp_X = X.exp()
    return exp_X/exp_X.sum()
```
即通过将每个$V_{i}$值减去数组V中最大值来起到降低exp()函数输入的作用,解决问题

第二个问题先看这个交叉熵函数,这里摘录动手学深度学习pytorch版本2.5节的代码,并非mxnet版本
```python
def cross_entropy(y_hat, y):
    return - torch.log(y_hat.gather(1, y.view(-1, 1)))
#其中数据为:
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])
y = torch.LongTensor([0, 2])
```
y.view(-1,1)使用了pytorch中的torch.view()函数,用来将y变换形态,其中的参数-1代表这个位置数值由其他值推断,所以应该得到
```python
print(y.view(-1,1))

tensor([[0],
        [2]])
```
理一下上面的,y_hat是两个数据对应3个类别的概率图,y是两个数据对应的类别标签,所以我们用gather取出对应类别的概率,输出为:
```python
tensor([[0.1000],
        [0.5000]])
```
参考<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.4_softmax-regression?id=_345-%e4%ba%a4%e5%8f%89%e7%86%b5%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0>
写的交叉熵函数,此处的$y_{j}$非1即0,所以我们的函数就被简化成$-log(\hat{y}_{i})$了

思考对数定义域为(0, -&),但是因为输出$\hat{y}$是softmax输出不应该存在负数(指数函数),应考虑点是如果$\hat{y}$输出过小时无限接近于0,该交叉熵函数即负对数函数结果值过大为nan
可以考虑在交叉熵中添加一极小值避免情况

以上全文参考文献:
[请问练习里的这两个问题有什么解决方案？我实在没想到，因为第一个exp(50)好大好大，第二个问题，ln定义域必须大于0，但根本不可能小于0啊，因为损失函数出来的值根本不会小于等于0啊](https://discuss.gluon.ai/t/topic/741/171)


## 对于分开定义不稳定的解决方法
虽然这句话有点nt,我们用一个包括两者的函数即可,数值稳定性会更好
pytorch中,这个函数称为:`nn.CrossEntropyLoss()`
该损失函数结合了nn.LogSoftmax()和nn.NLLLoss()两个函数,它在做分类（具体几类）训练的时候是非常有用的。
[torch官方文档:CROSSENTROPYLOSS](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)

## 激活函数,yyds
从联立后的式子可以看出，虽然神经网络引入了隐藏层，却依然等价于一个单层神经网络。不难发现，即便再添加更多的隐藏层，以上设计依然只能与仅含输出层的单层神经网络等价。
上述问题的根源在于全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。解决问题的一个方法是引入非线性变换，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。

摘自:<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.8_mlp?id=_382-%e6%bf%80%e6%b4%bb%e5%87%bd%e6%95%b0>

## CS231n讲解权重初始化
[CS231n课程笔记翻译：神经网络笔记 2](https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit)

## 如何理解训练误差和泛化误差(一个极好的例子,沐神666)
摘录链接:[3.11.1 训练误差和泛化误差](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.11_underfit-overfit?id=_3111-%e8%ae%ad%e7%bb%83%e8%af%af%e5%b7%ae%e5%92%8c%e6%b3%9b%e5%8c%96%e8%af%af%e5%b7%ae)

在解释上述现象之前，我们需要区分训练误差（training error）和泛化误差（generalization error）。通俗来讲，前者指模型在训练数据集上表现出的误差，后者指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。计算训练误差和泛化误差可以使用之前介绍过的损失函数，例如线性回归用到的平方损失函数和softmax回归用到的交叉熵损失函数。

让我们以高考为例来直观地解释训练误差和泛化误差这两个概念。训练误差可以认为是做往年高考试题（训练题）时的错误率，泛化误差则可以通过真正参加高考（测试题）时的答题错误率来近似。假设训练题和测试题都随机采样于一个未知的依照相同考纲的巨大试题库。如果让一名未学习中学知识的小学生去答题，那么测试题和训练题的答题错误率可能很相近。但如果换成一名反复练习训练题的高三备考生答题，即使在训练题上做到了错误率为0，也不代表真实的高考成绩会如此。

在机器学习里，我们通常假设训练数据集（训练题）和测试数据集（测试题）里的每一个样本都是从同一个概率分布中相互独立地生成的。基于该独立同分布假设，给定任意一个机器学习模型（含参数），它的训练误差的期望和泛化误差都是一样的。例如，如果我们将模型参数设成随机值（小学生），那么训练误差和泛化误差会非常相近。但我们从前面几节中已经了解到，模型的参数是通过在训练数据集上训练模型而学习出的，参数的选择依据了最小化训练误差（高三备考生）。所以，训练误差的期望小于或等于泛化误差。也就是说，一般情况下，由训练数据集学到的模型参数会使模型在训练数据集上的表现优于或等于在测试数据集上的表现。由于无法从训练误差估计泛化误差，一味地降低训练误差并不意味着泛化误差一定会降低。

机器学习模型应关注降低泛化误差。

## csv数据预处理
来源是<动手学>的房价预测,一直在做图像处理,还没怎么见过csv格式的处理,学习一下
[3.16.3 预处理数据](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.16_kaggle-house-price?id=_3163-%e9%a2%84%e5%a4%84%e7%90%86%e6%95%b0%e6%8d%ae)

# 20210122
今天算是农历新年前,工作的结束了,从明天开始就要为回家做准备了