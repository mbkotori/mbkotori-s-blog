# 表示图片时对格式的注意
注意： 由于像素值为0到255的整数，所以刚好是uint8所能表示的范围，包括transforms.ToTensor()在内的一些关于图片的函数就默认输入的是uint8型，若不是，可能不会报错但可能得不到想要的结果。所以，如果用像素值(0-255整数)表示图片数据，那么一律将其类型设置成uint8，避免不必要的bug。 本人就被这点坑过，详见<a href="https://tangshusen.me/2018/12/05/kaggle-doodle-reco/" target="_target">我的这个博客2.2.4节</a>。

以上摘自<https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.5_fashion-mnist?id=_351-%e8%8e%b7%e5%8f%96%e6%95%b0%e6%8d%ae%e9%9b%86>.

# 什么是模型微调
<a href="https://zhuanlan.zhihu.com/p/35890660">CNN入门讲解：什么是微调（Fine Tune）？</a>

# pytorch中的gather和scatter函数
先看看gather:
gather,单词中文释义为:聚集,集合
官方文档:
```python
torch.gather(input, dim, index, out=None) → Tensor
 
 Gathers values along an axis specified by dim.
 
 For a 3-D tensor the output is specified by:
 
 out[i][j][k] = input[index[i][j][k]][j][k] # dim=0
 out[i][j][k] = input[i][index[i][j][k]][k] # dim=1
 out[i][j][k] = input[i][j][index[i][j][k]] # dim=2
 
 Parameters: 
 
  input (Tensor) – The source tensor
  dim (int) – The axis along which to index
  index (LongTensor) – The indices of elements to gather
  out (Tensor, optional) – Destination tensor
 
 Example:
 
 >>> t = torch.Tensor([[1,2],[3,4]])
 >>> torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))
  1 1
  4 3
 [torch.FloatTensor of size 2x2]
```

可以看到,gather是根据我们给的索引index在input中数据得到out,其中除了index外输出还会受到dim的影响,下面用张图直观表示下
![](http://ys-f.ys168.com/614621469/813404410/iohprkk534471377NHVd0/gather%E8%A7%A3%E9%87%8A%E5%9B%BE.png)

再看看scatter:
scatter中文释义:撒,撒播,散开

这个函数则是将数据根据索引回填到一个新矩阵中,根据它的功能我们很适合拿他来做onehot矩阵
同样应有输入input,操作维度dim,索引index,我们同样利用一张图片李姐:
![](http://ys-j.ys168.com/614621458/813404548/w7425552H85NJmndqtlb8/scatter%E8%A7%A3%E9%87%8A%E5%9B%BE.jpg)

以下列出几个参考网站,方便读者进行进一步阅读理解:
[Pytorch的gather和scatter](https://blog.csdn.net/loovelj/article/details/107639701)
[3分钟理解 pytorch 的 gather 和 scatter](https://zhuanlan.zhihu.com/p/319191164)
[torch.gather/scatter_使用](https://zhuanlan.zhihu.com/p/59346637)

# 一个没看懂的代码
```python
def accuracy(y_hat, y):
    return (y_hat.argmax(dim=1) == y).float().mean().item()
```
用来计算`y_hat`和`y`的准确率
```python
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])
y = torch.LongTensor([0, 2])
```

理一下思路,首先其中y_hat.argmax(dim=1)返回矩阵y_hat每行中最大元素的索引，且返回结果与变量y形状相同。
即`print(y_hat.argmax(dim=1)) = tensor([2,2])`
然后做相等判断式,和y进行比较,判断式输出为:[False, true],是一个类型为`ByteTensor`的Tensor，我们用float()将其转换为值为0（相等为假）或1（相等为真）的浮点型Tensor。
也就是到此处为:print((y_hat.argmax(dim=1) == y).float()) = tensor([0., 1.])
注:`ByteTensor`在c语言中对应的话,可以看作无符号字符串
对tensor([0., 1.])做torch.mean()操作,默认不设置dim时返回所有元素的平均值,设置dim后则按维度给返回值
此处输出则为(0+1)/2=0.5.
```python
print(accuracy(y_hat, y))
```
输出:
```python
0.5
```
最后结尾的item()用法则是得到一个元素张量里面的元素值,如果不使用item,输出应为:
```python
tensor(0.5000)
```























